{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "970217a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Tuple\n",
    "\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28401dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Data\n",
      "Loaded Data\n",
      "Number of Images : Threes -> 6131, Sevens -> 6265\n",
      "Converted into Tensors...\n",
      "An image has a size of : torch.Size([784])\n",
      "Built Dataset & Dataloaders\n",
      "| Epoch 0 |\n",
      "Train Loss : 1063.31, Valid Accuracy : 95.39%\n",
      "\n",
      "| Epoch 1 |\n",
      "Train Loss : 378.21, Valid Accuracy : 96.25%\n",
      "\n",
      "| Epoch 2 |\n",
      "Train Loss : 327.99, Valid Accuracy : 96.57%\n",
      "\n",
      "| Epoch 3 |\n",
      "Train Loss : 304.01, Valid Accuracy : 96.52%\n",
      "\n",
      "| Epoch 4 |\n",
      "Train Loss : 288.77, Valid Accuracy : 96.72%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "logging.basicConfig(filename='mnist.log', level=logging.INFO)\n",
    "def custom_logger(text):\n",
    "\tlogging.info(text)\t\n",
    "\tprint(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1c1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "\tdef __init__(self, data, labels, split=None, shuffle=True):\n",
    "\t\tif isinstance(data, list): data = tensor(data)\n",
    "\t\tif isinstance(labels, list): labels = tensor(labels)    \n",
    "            \n",
    "\t\tif data.shape[0] != labels.shape[0]:\n",
    "\t\t\traise ValueError(\"The data and labels shapes don't match\")\n",
    "            \n",
    "\t\tif shuffle is True:\n",
    "\t\t\tindexes = torch.randperm(data.shape[0])\n",
    "\t\t\tdata = data[indexes]\n",
    "\t\t\tlabels = labels[indexes]\n",
    "            \n",
    "\t\tif split:\n",
    "\t\t\tsplit_int = int(data.shape[0] * split)    \n",
    "\t\t\tself.train = Dataset(data[:split_int], labels[:split_int])\n",
    "\t\t\tself.valid = Dataset(data[split_int:], labels[split_int:])\n",
    "\t\t\n",
    "\t\tself.data = data\n",
    "\t\tself.labels = labels\n",
    "\t\t\n",
    "\tdef __getitem__(self, key):\n",
    "\t\treturn (self.data[key],self.labels[key])\n",
    "\n",
    "\tdef __iter__(self):\n",
    "\t\treturn iter((self.data, self.labels))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.data.shape[0] # could any of them\n",
    "    \n",
    "def Dataloader(ds, bs=100):\n",
    "    return [ds[pos:pos + bs] for pos in range(0, len(ds), bs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "415b0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Pass Funcs\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + torch.exp(-z))\n",
    "\n",
    "def linear1(x, w, b):\n",
    "    return x@w + b\n",
    "\n",
    "def predict(x:torch.Tensor, w, b) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    x1 = linear1(x, w, b)\n",
    "    res = sigmoid(x1)\n",
    "    return (res > .5).float(), res #labels, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c2f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss & Metric\n",
    "def mnist_loss(y, ypred) -> torch.Tensor:\n",
    "    return torch.where(y == 1., 1.-ypred, ypred).sum()\n",
    "\n",
    "def accuracy(y, ypred) -> float:\n",
    "    return (y == ypred).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e8dcd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Procedures\n",
    "def init_params(size):\n",
    "    w = torch.randn(size).requires_grad_()\n",
    "    b = torch.randn(1).requires_grad_()\n",
    "    return (w, b)\n",
    "\n",
    "def optimize(loss, w, b, lr):\n",
    "    loss.backward()\n",
    "    w.data -= lr*w.grad\n",
    "    b.data -= lr*b.grad\n",
    "    w.grad = None\n",
    "    b.grad = None\n",
    "    \n",
    "def validate_model(w, b, valid_dl):\n",
    "    with torch.no_grad():\n",
    "        val_loss = tensor(0.)\n",
    "        val_accs = []\n",
    "        for x, y in valid_dl:\n",
    "            labels, yprobs = predict(x, w, b)\n",
    "            val_loss += mnist_loss(y, yprobs) # Batch Loss\n",
    "            val_accs.append(accuracy(y, labels)) # Batch Acc\n",
    "\n",
    "    return val_loss.item(), torch.stack(val_accs).mean().item() #Overall Loss, Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d6f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross-entropy-loss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
